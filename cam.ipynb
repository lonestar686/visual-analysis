{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Activation Mapping In PyTorch\n",
    "Have you ever wondered just how a neural network model like ResNet decides on its decision to determine that an image is a cat or a flower in the field? Class Activation Mappings (CAM) can provide some insight into this process by overlaying a heatmap over the original image to show us where our model thought most strongly that this cat was indeed a cat.\n",
    "\n",
    "Firstly, we’re going to need a picture of a cat. And thankfully, here’s one I took earlier of a rather suspicious cat that is wondering why the strange man is back in his house again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.transform\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from torch.nn import functional as F\n",
    "from torch import topk\n",
    "\n",
    "import io\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet class-index-label\n",
    "import json\n",
    "\n",
    "# on cloud\n",
    "# LABELS_URL = 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'\n",
    "\n",
    "# at local disk\n",
    "LABELS_URL = \"./imagenet_class_index.json\"\n",
    "\n",
    "# {\"0\": [\"n01440764\", \"tench\"], \"1\": [\"n01443537\", \"goldfish\"], \"2\": [\"n01484850\", \"great_white_shark\"], ...}\n",
    "\n",
    "idx2label = []\n",
    "cls2label = {}\n",
    "# load imagenet class-index\n",
    "with open(LABELS_URL, \"r\") as read_file:\n",
    "    class_indices = json.load(read_file)\n",
    "    # convert index or class name to label\n",
    "    idx2label = [class_indices[str(k)][1] for k in range(len(class_indices))]\n",
    "    cls2label = {class_indices[str(k)][0]: class_indices[str(k)][1] for k in range(len(class_indices))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image\n",
    "IMG_URL = 'http://media.mlive.com/news_impact/photo/9933031-large.jpg'\n",
    "IMG_URL = 'https://cdn.pixabay.com/photo/2017/02/20/18/03/cat-2083492__340.jpg'\n",
    "IMG_URL = 'https://cdn.pixabay.com/photo/2018/03/26/20/49/tiger-3264048__340.jpg'\n",
    "IMG_URL = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSyOX2T4HLkL_PUaMgKoo6q_NTk0thueXbRN3OAI-2fRyRz4E0iEg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(IMG_URL)\n",
    "image = Image.open(io.BytesIO(response.content))\n",
    "\n",
    "# image = Image.open(\"casper2.png\")\n",
    "imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn’t he look worried? Next, we’re going to set up some torchvision transforms to scale the image to the 224x224 required for ResNet and also to normalize it to the ImageNet mean/std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagenet mean/std\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "# Preprocessing - scale to 224x224 for model, convert to tensor, \n",
    "# and normalize to -1..1 with mean/std for ImageNet\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize((224,224)),\n",
    "   transforms.ToTensor(),\n",
    "   normalize\n",
    "])\n",
    "\n",
    "display_transform = transforms.Compose([\n",
    "   transforms.Resize((224,224))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = preprocess(image)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_var = tensor.unsqueeze(0).cuda()\n",
    "prediction_var.requires_grad_();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having converted our image into a PyTorch variable, we need a model to generate a prediction. Let’s use ResNet18, put it in evaluation mode, and stick it on the GPU using the CUDA libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next bit of code is swiped from Jeremy Howard’s fast.ai course. It basically allows you to easily attach a hook to any model (or any part of a model - here we’re going to grab the final convnet layer in ResNet18) which will save the activation features as an instance variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = ((output.cpu()).data).numpy()\n",
    "    def remove(self): self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_layer = model._modules.get('layer4')\n",
    "\n",
    "activated_features = SaveFeatures(final_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having set that up, we run the image through our model and get the prediction. We then run that through a softmax layer to turn that prediction into a series of probabilities for each of the 1000 classes in ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(prediction_var)\n",
    "pred_probabilities = F.softmax(prediction).data.squeeze()\n",
    "activated_features.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using topk(), we can see that our model is 78% confident that this picture is class 283. Looking that up in the ImageNet classes, that gives us…’persian cat’. I would say that’s not a bad guess!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk(pred_probabilities,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having made the guess, let’s see where the neural network was focussing its attention. The getCAM() method here takes the activated features of the convnet, the weights of the fully-connected layer (on the side of the average pooling), and the class index we want to investigate (283/‘persian cat’ in our case). We index into the fully-connected layer to get the weights for that class and calculate the dot product with our features from the image.\n",
    "\n",
    "(this code is based on the paper that introduced CAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCAM(feature_conv, weight_fc, class_idx):\n",
    "    _, nc, h, w = feature_conv.shape\n",
    "    cam = weight_fc[class_idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "    cam = cam.reshape(h, w)\n",
    "    cam = cam - np.min(cam)\n",
    "    cam_img = cam / np.max(cam)\n",
    "    return cam_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_softmax_params = list(model._modules.get('fc').parameters())\n",
    "weight_softmax = np.squeeze(weight_softmax_params[0].cpu().data.numpy())\n",
    "weight_softmax_params;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, indices = topk(pred_probabilities,1)\n",
    "probs, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_index = 0\n",
    "\n",
    "# convert to cpu\n",
    "prob = probs[top_index].item() * 100\n",
    "class_idx = indices[top_index].item()\n",
    "\n",
    "# get CAM\n",
    "overlay = getCAM(activated_features.features, weight_softmax, class_idx )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "prob, class_idx, idx2label[class_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see our heatmap and overlay it onto Casper. It doesn’t make him look any happier, but we can see exactly where the model made its mind up about him."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(overlay, cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(skimage.transform.resize(overlay, tensor.shape[1:3]), cmap='jet');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(display_transform(image))\n",
    "imshow(skimage.transform.resize(overlay, tensor.shape[1:3]), alpha=0.5, cmap='jet');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait, there’s a bit more - we can also look at the model’s second choice for Casper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, indices = topk(pred_probabilities,2)\n",
    "probs, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_index = 1\n",
    "\n",
    "# convert to cpu\n",
    "prob = probs[top_index].item() * 100\n",
    "class_idx = indices[top_index].item()\n",
    "\n",
    "# get CAM\n",
    "overlay = getCAM(activated_features.features, weight_softmax, class_idx )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "prob, class_idx, idx2label[class_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(display_transform(image))\n",
    "imshow(skimage.transform.resize(overlay, tensor.shape[1:3]), alpha=0.5, cmap='jet');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the heatmap is similar, the network is focussing a touch more on his fluffy coat to suggest he might be class 332 - an Angora rabbit. And well, he is a Turkish Angora cat after all…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
